{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "964dec49-6016-428a-b4c3-5d45b351c9c7",
   "metadata": {},
   "source": [
    "AI-Driven Epidemiological Modeling for Non-Communicable Disease (NCD) Trends\n",
    "Introduction\n",
    "Non-Communicable Diseases (NCDs) — including cardiovascular diseases, diabetes, cancer, and chronic respiratory conditions — are a major global health burden. Understanding the progression and trends of these diseases is crucial for effective public health planning and intervention strategies.\n",
    "\n",
    "This project utilizes Artificial Intelligence (AI) and Machine Learning (ML) techniques to build epidemiological models that predict and analyze NCD trends over time. By leveraging historical data, the model identifies patterns and provides insights into how NCD prevalence may evolve, supporting data-driven decision-making for healthcare systems.\n",
    "\n",
    "Objectives\n",
    "To model the time series progression of NCDs using AI algorithms.\n",
    "To identify key factors influencing NCD trends (age, lifestyle, socio-economic status, etc.).\n",
    "To forecast future NCD incidences and assess the impact of potential interventions.\n",
    "Methodology\n",
    "The workflow includes:\n",
    "\n",
    "Data Acquisition and Preprocessing: Collecting time-series health data, cleaning, and handling missing values.\n",
    "Exploratory Data Analysis (EDA): Visualizing historical trends and correlations.\n",
    "Model Development: Using algorithms like ARIMA, LSTM, and XGBoost for trend prediction.\n",
    "Model Evaluation: Assessing model accuracy using metrics like RMSE, MAE, and R².\n",
    "Interpretability: Applying explainable AI (XAI) tools to highlight influential risk factors.\n",
    "Tools and Libraries\n",
    "Python: NumPy, Pandas, Matplotlib, Seaborn\n",
    "ML Libraries: Scikit-learn, TensorFlow, Keras\n",
    "Time Series Analysis: Statsmodels, Prophet\n",
    "Data Visualization: Plotly, Seaborn\n",
    "Notebooks: Jupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b898e6-4d5d-4c93-a16f-d347c67a047d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "# Load dataset properly\n",
    "file_path = r\"C:\\Users\\91973\\Downloads\\Project 2.xlsx\"\n",
    "df = pd.read_excel(file_path, engine='openpyxl')\n",
    "# Drop irrelevant columns (keep only numeric)\n",
    "df = df.select_dtypes(include=[np.number])\n",
    "# Remove rows with missing target values\n",
    "target_col = 'VALUE_NUMERIC'\n",
    "df = df.dropna(subset=[target_col])\n",
    "# Handle missing values in features\n",
    "df.fillna(df.median(numeric_only=True), inplace=True)\n",
    "# Outlier Removal using IQR\n",
    "Q1 = df[target_col].quantile(0.25)\n",
    "Q3 = df[target_col].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "df = df[(df[target_col] >= lower_bound) & (df[target_col] <= upper_bound)]\n",
    "# Define Features & Target\n",
    "X = df.drop(columns=[target_col])\n",
    "y = df[target_col]\n",
    "# Standardize Features & Target\n",
    "scaler_X = StandardScaler()\n",
    "X_scaled = scaler_X.fit_transform(X)\n",
    "scaler_y = StandardScaler()\n",
    "y_scaled = scaler_y.fit_transform(y.values.reshape(-1, 1)).flatten() # Standardize target\n",
    "# Train-Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_scaled, test_size=0.2, random_state=42)\n",
    "# Model Training\n",
    "model = RandomForestRegressor(n_estimators=200, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "# Predictions\n",
    "y_pred_scaled = model.predict(X_test)\n",
    "# Convert predictions back to original scale\n",
    "y_pred = scaler_y.inverse_transform(y_pred_scaled.reshape(-1, 1)).flatten()\n",
    "y_test_original = scaler_y.inverse_transform(y_test.reshape(-1, 1)).flatten()\n",
    "# Performance Metrics\n",
    "mae = mean_absolute_error(y_test_original, y_pred)\n",
    "mse = mean_squared_error(y_test_original, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test_original, y_pred)\n",
    "print(f\" Model Performance Metrics:\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.2f}\")\n",
    "print(f\"Mean Squared Error (MSE): {mse:.2f}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse:.2f}\")\n",
    "print(f\"R-Squared (R²): {r2:.4f}\")\n",
    "# Scatter Plot for Predictions\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.scatter(y_test_original, y_pred, alpha=0.5)\n",
    "plt.xlabel(\"Actual Values\")\n",
    "plt.ylabel(\"Predicted Values\")\n",
    "plt.title(\"Actual vs Predicted Values\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
