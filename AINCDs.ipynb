{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ede1e80-611b-4c31-9ac0-0c576975d5c4",
   "metadata": {},
   "source": [
    "AI-Based Early Prediction of Non-Communicable Diseases (NCDs)\n",
    "Introduction\n",
    "Non-Communicable Diseases (NCDs), such as cardiovascular diseases, diabetes, cancer, and chronic respiratory diseases, are among the leading causes of death globally. Early prediction and intervention can significantly reduce mortality rates and improve patient outcomes.\n",
    "\n",
    "This project leverages Artificial Intelligence (AI) and Machine Learning (ML) techniques to develop a predictive model capable of identifying individuals at risk of NCDs based on clinical, demographic, and lifestyle data.\n",
    "\n",
    "Objectives\n",
    "To collect and preprocess relevant datasets containing NCD risk factors.\n",
    "To build and evaluate machine learning models for early NCD prediction.\n",
    "To identify key features contributing to NCD risk using explainable AI (XAI) techniques.\n",
    "Methodology\n",
    "The workflow involves the following steps:\n",
    "\n",
    "Data Collection and Cleaning: Sourcing open-access datasets, handling missing values, and normalizing data.\n",
    "Exploratory Data Analysis (EDA): Visualizing trends, correlations, and outliers.\n",
    "Model Selection: Testing various ML algorithms (Logistic Regression, Random Forest, etc.).\n",
    "Model Evaluation: Using metrics like accuracy, precision, recall, F1-score, and ROC-AUC curves.\n",
    "Interpretability: Implementing SHAP or LIME to highlight the most influential risk factors.\n",
    "Tools and Libraries\n",
    "Python: NumPy, Pandas, Matplotlib, Seaborn\n",
    "ML Libraries: Scikit-learn, TensorFlow/PyTorch\n",
    "Data Visualization: Plotly, Seaborn\n",
    "Notebooks: Jupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "761f0332-df30-445b-94e0-b8fa6f07c974",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "# Load dataset\n",
    "file_path = r\"C:\\Users\\91973\\Downloads\\project 1.xlsx\"\n",
    "df = pd.read_excel(file_path, engine='openpyxl')\n",
    "# Display dataset info before cleaning\n",
    "print(\"\\nDataset Info Before Cleaning:\")\n",
    "print(df.info())\n",
    "# Drop irrelevant columns if necessary (modify as needed)\n",
    "df = df.drop(columns=[\"encounter_id\", \"patient_n\"], errors='ignore')\n",
    "# Handle missing values\n",
    "df.replace(\"?\", np.nan, inplace=True) # Convert '?' to NaN\n",
    "df.fillna(df.median(numeric_only=True), inplace=True) # Fill NaN with column medians\n",
    "df.fillna(df.mode().iloc[0], inplace=True) # Fill remaining NaNs with mode (for categorical)\n",
    "# Check if dataset is still valid\n",
    "if df.shape[0] == 0:\n",
    " raise ValueError(\"Dataset is empty after preprocessing!\")\n",
    "# Encode categorical variables\n",
    "categorical_columns = df.select_dtypes(include=['object']).columns\n",
    "label_encoders = {}\n",
    "for col in categorical_columns:\n",
    " le = LabelEncoder()\n",
    " df[col] = le.fit_transform(df[col].astype(str)) # Convert non-numeric data\n",
    " label_encoders[col] = le\n",
    "# Define features (X) and target (y)\n",
    "target_column = \"A1Cresult\" # Change this to the correct target column\n",
    "if target_column not in df.columns:\n",
    " raise ValueError(f\"Target column '{target_column}' not found in dataset!\")\n",
    "X = df.drop(columns=[target_column])\n",
    "y = df[target_column]\n",
    "# Standardize numerical features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "# Split dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "# Display dataset shape after processing\n",
    "print(f\"Training Data Shape: {X_train.shape}, Testing Data Shape: {X_test.shape}\")\n",
    "# Train Random Forest model\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "# Make predictions\n",
    "y_pred = clf.predict(X_test)\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"\\nModel Accuracy: {accuracy:.2f}\")\n",
    "# Classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "# Confusion matrix visualization\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt='d', cmap=\"Blues\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n",
    "# Feature importance visualization\n",
    "feature_importance = pd.Series(clf.feature_importances_, \n",
    "index=X.columns).sort_values(ascending=False)\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.barplot(x=feature_importance, y=feature_importance.index)\n",
    "plt.xlabel(\"Feature Importance\")\n",
    "plt.ylabel(\"Features\")\n",
    "plt.title(\"Feature Importance from Random Forest\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
